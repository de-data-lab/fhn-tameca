{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e7a33e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import psycopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1c7aa8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Pulse_May_2020_survey_public_data.csv',\n",
       " '.DS_Store',\n",
       " 'Pulse_Aug_2020_survey_public_data.csv',\n",
       " 'csv_import_automation.ipynb',\n",
       " 'pulse_2018_import.ipynb',\n",
       " 'Pulse_2018_survey_public_data.csv',\n",
       " '.ipynb_checkpoints',\n",
       " 'Pulse_2019_survey_public_data.csv',\n",
       " 'Pulse_2021_survey_public_data.csv']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#find csv files in current working directory\n",
    "os.listdir(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd5f406b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#isolate only csv files with a for loop\n",
    "csv_files = []\n",
    "for file in os.listdir(os.getcwd()):\n",
    "    if file.endswith('.csv'):\n",
    "        csv_files.append(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4df44dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a new directory\n",
    "dataset_dir = 'datasets'\n",
    "#create bash command to make a new dir\n",
    "#mkdir dataset_dir\n",
    "\n",
    "try:\n",
    "    mkdir = 'mkdir {0}'.format(dataset_dir)\n",
    "    os.system(mkdir)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ed1e35f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mv 'Pulse_May_2020_survey_public_data.csv' datasets\n",
      "mv 'Pulse_Aug_2020_survey_public_data.csv' datasets\n",
      "mv 'Pulse_2018_survey_public_data.csv' datasets\n",
      "mv 'Pulse_2019_survey_public_data.csv' datasets\n",
      "mv 'Pulse_2021_survey_public_data.csv' datasets\n"
     ]
    }
   ],
   "source": [
    "#move the csv files to the new directory\n",
    "\n",
    "#mv filename directory\n",
    "for csv in csv_files:\n",
    "    mv_file = \"mv '{0}' {1}\".format(csv, dataset_dir)\n",
    "    os.system(mv_file)\n",
    "    print(mv_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8596800d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yr/hk4ztld11c53hnlmp45js6000000gn/T/ipykernel_28987/2555810783.py:7: DtypeWarning: Columns (9,10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df[file] = pd.read_csv(data_path+file)\n",
      "/var/folders/yr/hk4ztld11c53hnlmp45js6000000gn/T/ipykernel_28987/2555810783.py:7: DtypeWarning: Columns (9,10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df[file] = pd.read_csv(data_path+file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pulse_May_2020_survey_public_data.csv\n",
      "Pulse_Aug_2020_survey_public_data.csv\n",
      "Pulse_2018_survey_public_data.csv\n",
      "Pulse_2019_survey_public_data.csv\n",
      "Pulse_2021_survey_public_data.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yr/hk4ztld11c53hnlmp45js6000000gn/T/ipykernel_28987/2555810783.py:7: DtypeWarning: Columns (9,10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df[file] = pd.read_csv(data_path+file)\n"
     ]
    }
   ],
   "source": [
    "#dataframe\n",
    "data_path = os.getcwd()+'/'+dataset_dir+'/'\n",
    "\n",
    "df = {}\n",
    "for file in csv_files:\n",
    "    try:\n",
    "        df[file] = pd.read_csv(data_path+file)\n",
    "    except UnicodeDecodeError:\n",
    "        df[file] = pd.read_csv(data_path+file, encoding=\"ISO-8859-1\", low_memory=False)\n",
    "    print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "26e10b6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pulse_may_2020_survey_public_data\n",
      "opened database successfully\n",
      "pulse_may_2020_survey_public_data was created successfully\n",
      "file opened in memory\n",
      "file copied to db\n",
      "table pulse_may_2020_survey_public_data imported to db completed\n",
      "all tables have been successfully imported into the database\n",
      "pulse_aug_2020_survey_public_data\n",
      "opened database successfully\n",
      "pulse_aug_2020_survey_public_data was created successfully\n",
      "file opened in memory\n",
      "file copied to db\n",
      "table pulse_aug_2020_survey_public_data imported to db completed\n",
      "all tables have been successfully imported into the database\n",
      "pulse_2018_survey_public_data\n",
      "opened database successfully\n",
      "pulse_2018_survey_public_data was created successfully\n",
      "file opened in memory\n",
      "file copied to db\n",
      "table pulse_2018_survey_public_data imported to db completed\n",
      "all tables have been successfully imported into the database\n",
      "pulse_2019_survey_public_data\n",
      "opened database successfully\n",
      "pulse_2019_survey_public_data was created successfully\n",
      "file opened in memory\n",
      "file copied to db\n",
      "table pulse_2019_survey_public_data imported to db completed\n",
      "all tables have been successfully imported into the database\n",
      "pulse_2021_survey_public_data\n",
      "opened database successfully\n",
      "pulse_2021_survey_public_data was created successfully\n",
      "file opened in memory\n",
      "file copied to db\n",
      "table pulse_2021_survey_public_data imported to db completed\n",
      "all tables have been successfully imported into the database\n"
     ]
    }
   ],
   "source": [
    "# clean table names\n",
    "# lowercase, replace whitespace with _, replace symbols with _\n",
    "\n",
    "for k in csv_files:\n",
    "    dataframe = df[k]\n",
    "\n",
    "    clean_table_name = k.lower().replace(\" \", \"_\").replace(\"?\", \"\") \\\n",
    "                    .replace(\"-\", \"_\").replace(r\"/\", \"_\").replace(\"\\\\\", \"_\").replace(\"%\", \"\") \\\n",
    "                    .replace(\")\", \"\").replace(r\"(\",\"\").replace(\"$\",\"\")\n",
    "  \n",
    "    \n",
    "    #remove .csv extention from clean table name\n",
    "    tbl_name = '{0}'.format(clean_table_name.split('.')[0])\n",
    "    print(tbl_name)\n",
    "    \n",
    "    dataframe.columns = [x.lower().replace(\" \", \"_\").replace(\"?\", \"\") \\\n",
    "                    .replace(\"-\", \"_\").replace(r\"/\", \"_\").replace(\"\\\\\", \"_\").replace(\"%\", \"\") \\\n",
    "                    .replace(\")\", \"\").replace(r\"(\",\"\").replace(\"$\",\"\") for x in dataframe.columns]\n",
    "  \n",
    "    \n",
    "    #create replacements dictionary that maps panda dtypes to sql dtypes\n",
    "    replacements = {\n",
    "    'object' : 'varchar',\n",
    "    'float64': 'float',\n",
    "    'int64': 'int',\n",
    "    'datetime64': 'timestamp',\n",
    "    'timedelta64[ns]':'varchar'\n",
    "    }\n",
    "    \n",
    "    #create the create table schema - join name and datatype, replacing the pandas dtype with sql datatype as loop\n",
    "    col_string = \", \".join(\"{} {}\".format(n, d) for (n, d) in zip(dataframe.columns, dataframe.dtypes.replace(replacements)))\n",
    "   \n",
    "    \n",
    "    #open database connection to postgres using psycopg2\n",
    "    host = 'localhost'\n",
    "    dbname = 'FHN'\n",
    "    user = 'user'\n",
    "    password = 'password'\n",
    "    conn_string = \"host=%s dbname=%s user=%s password=%s\" % (host, dbname, user, password)\n",
    "\n",
    "    conn = psycopg2.connect(conn_string)\n",
    "    cursor = conn.cursor()\n",
    "    print('opened database successfully')\n",
    "\n",
    "    #drop tables with same name\n",
    "    cursor.execute(\"drop table if exists %s;\" % (tbl_name))\n",
    "\n",
    "    #CREATE TABLE\n",
    "    cursor.execute(\"create table %s (%s);\" % (tbl_name, col_string))\n",
    "    print('{0} was created successfully'.format(tbl_name))\n",
    "\n",
    "    #insert values to table\n",
    "\n",
    "    #save df to csv\n",
    "    dataframe.to_csv(k, header=dataframe.columns, index=False, encoding='utf-8')\n",
    "\n",
    "    #open csv files, save as an object\n",
    "    my_file = open(k)\n",
    "    print('file opened in memory')\n",
    "\n",
    "    #upload to db\n",
    "    SQL_STATEMENT = \"\"\"\n",
    "    COPY %s FROM STDIN WITH\n",
    "        CSV\n",
    "        HEADER\n",
    "        DELIMITER AS ','\n",
    "    \"\"\"\n",
    "\n",
    "    cursor.copy_expert(sql=SQL_STATEMENT % tbl_name, file=my_file)\n",
    "    print('file copied to db')\n",
    "\n",
    "    conn.commit()\n",
    "    cursor.close\n",
    "    print('table {0} imported to db completed'.format(tbl_name))\n",
    "\n",
    "    #for loop end message\n",
    "    print('all tables have been successfully imported into the database')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15436ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
